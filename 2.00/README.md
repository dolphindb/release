# DolphinDB Release Notes

- [DolphinDB Release Notes](#dolphindb-release-notes)
  - [DolphinDB Server](#dolphindb-server)
    - [New Features](#new-features)
    - [Improvements](#improvements)
    - [Issues Fixed](#issues-fixed)
  - [Web-Based User Interface](#web-based-user-interface)

## DolphinDB Server

Version: **2.00.10** &nbsp;&nbsp;&nbsp; [Compatibility Level 1](https://github.com/dolphindb/release/blob/master/DolphinDB_compatibility_levels_EN.md#32-compatibility-level-1) with 2.00.9/1.30.21&nbsp;&nbsp;&nbsp; For details, see [Compatibility Changes in Version 2.00.10](https://github.com/dolphindb/release/blob/master/compatibility_changes.md#version-20010)

Release Date: 2023-07-20

[Linux64 binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.10.zip) | 
[Linux64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.10_JIT.zip) | 
[Linux64 ABI binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.10_ABI.zip) | 
[Windows64 binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.10.zip) |
[Windows64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.10_JIT.zip)
[Linux ARM64](https://www.dolphindb.com/downloads/DolphinDB_ARM64_V2.00.10.zip)

Version: **2.00.9** &nbsp;&nbsp;&nbsp; [Compatibility Level 2](https://github.com/dolphindb/release/blob/master/DolphinDB_compatibility_levels_EN.md#32-compatibility-level-2) with 2.00.8/1.30.20

Release Date: 2023-02-15

[Linux64 binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.9.7.zip) | 
[Linux64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.9.7_JIT.zip) | 
[Linux64 ABI binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.9.7_ABI.zip) | 
[Windows64 binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.9.7.zip) |
[Windows64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.9.7_JIT.zip) |
[Linux ARM64](https://www.dolphindb.com/downloads/DolphinDB_ARM64_V2.00.9.1.zip)


Version: **2.00.8** &nbsp;&nbsp;&nbsp; [Compatibility Level 2](https://github.com/dolphindb/release/blob/master/DolphinDB_compatibility_levels_EN.md#32-compatibility-level-2) with 2.00.7/1.30.19

Release Date: 2022-09-30

[Linux64 binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.8.zip) | 
[Linux64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.8_JIT.zip) | 
[Linux64 ABI binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.8_ABI.zip) | 
[Windows64 binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.8.zip) |
[Windows64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.8_JIT.zip) |
[Linux ARM64](https://www.dolphindb.com/downloads/DolphinDB_ARM64_V2.00.8.zip)

Version: **2.00.7** &nbsp;&nbsp;&nbsp; [Compatibility Level 1](https://github.com/dolphindb/release/blob/master/DolphinDB_compatibility_levels_EN.md#31-compatibility-level-1) with 2.00.6

Release Date: 2022-07-14

[Linux64 binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.7.zip) | 
[Linux64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.7_JIT.zip) | 
[Linux64 ABI binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.7_ABI.zip) | 
[Windows64 binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.7.zip) |
[Windows64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.7_JIT.zip) |
[Linux ARM64](https://www.dolphindb.com/downloads/DolphinDB_ARM64_V2.00.7.zip) 

Version: **2.00.6** &nbsp;&nbsp;&nbsp; [Compatibility Level 2](https://github.com/dolphindb/release/blob/master/DolphinDB_compatibility_levels_EN.md#32-compatibility-level-2) with 2.00.5

Release Date: 2022-05-09

[Linux64 binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.6.zip) | 
[Linux64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.6_JIT.zip) | 
[Linux64 ABI binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.6_ABI.zip) | 
[Windows64 binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.6.zip) |
[Windows64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.6_JIT.zip) 

Version: **2.00.5** &nbsp;&nbsp;&nbsp; [Compatibility Level 2](https://github.com/dolphindb/release/blob/master/DolphinDB_compatibility_levels_EN.md#32-compatibility-level-2) with 2.00.4/1.30.16/1.30.17

Release Date: 2022-03-29

[Linux64 binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.5.zip) | 
[Linux64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.5_JIT.zip) | 
[Linux64 ABI binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.5_ABI.zip) | 
[Windows64 binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.5.zip) |
[Windows64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.00.5_JIT.zip) 

Version: **2.00.4**

Release Date: 2022-01-10

[Linux64 binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.4.zip) | 
[Linux64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.4_JIT.zip) | 
[Linux64 ABI binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.00.4_ABI.zip) 

Version: **2.0.0**

Release Date: 2021-07-31

[Linux64 binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.0.0.zip) | 
[Linux64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.0.0_JIT.zip) | 
[Linux64 ABI binary](https://www.dolphindb.com/downloads/DolphinDB_Linux64_V2.0.0_ABI.zip) | 
[Windows64 binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.0.0.zip) |
[Windows64 JIT binary](https://www.dolphindb.com/downloads/DolphinDB_Win64_V2.0.0_JIT.zip)


### New Features

- Added support for `RIGHT JOIN` on multiple DFS tables. (**2.00.10**)

- Added configuration parameter *memLimitOfTempResult* and function `setMemLimitOfTempResult` to set the upper limit of memory usage for each temporary result generated in the table join operation. (**2.00.10**)

- Added configuration parameter *tempResultsSpillDir* to specify the spill directory storing the temporary results generated in the table join operation. (**2.00.10**)
  
- Added configuration parameter *enableCoreDump* to enable core dumps. It is only supported on Linux. (**2.00.10**)
  
- Added configuration parameter *disableCoreDumpOnShutdown* to specify whether to generate core dumps on a graceful shutdown. It is only supported on Linux. (**2.00.10**)
  
- Added configuration parameter *allowMissingPartitions* to specify the behavior when incoming data contains new partition values that do not match any existing partitions. (**2.00.10**)

- Added configuration parameter *volumeUsageThreshold* to set the upper limit of the disk usage of a data node. (**2.00.10**)

- Added function `listRemotePlugins` to obtain a list of available plugins. Added function `installPlugin` to download a plugin. (**2.00.10**)

- Added function `writeLogLevel` to write logs of the specified level to the log file. (**2.00.10**)
  
- Added function `sessionWindow` to group time-series data based on the session intervals. (**2.00.10**)
  
- Added function `summary` to generate summary statistics of input data, including min, max, count, avg, std, and percentiles. (**2.00.10**)

- Added functions `encodeShortGenomeSeq` and `decodeShortGenomeSeq` to encode and decode DNA sequences. (**2.00.10**)
  
- Added function `genShortGenomeSeq` to perform DNA sequence encoding within a sliding window. (**2.00.10**)
  
- Added function `gramSchmidt` to implement the Gram–Schmidt orthonormalization. (**2.00.10**)
  
- Added function `lassoBasic` that has equivalent function to `lasso` but takes vectors as input arguments. (**2.00.10**)
  
- Added 26 TopN functions: (**2.00.10**)
  - m-functions：`mskewTopN`, `mkurtosisTopN`
  - cum-functions：`cumsumTopN`, `cumavgTopN`, `cumstdTopN`, `cumstdpTopN`, `cumvarTopN`, `cumvarpTopN`, `cumbetaTopN`, `cumcorrTopN`, `cumcovarTopN`, `cumwsumTopN`, `cumskewTopN`, `cumkurtosisTopN`
  - tm-functions：`tmsumTopN`, `tmavgTopN`, `tmstdTopN`, `tmstdpTopN`, `tmvarTopN`, `tmvarpTopN`, `tmbetaTopN`, `tmcorrTopN`, `tmcovarTopN`, `tmwsumTopN`, `tmskewTopN`, `tmkurtosisTopN`
  
- Added function `initcap` to set the first letter of each word in a string to uppercase and the rest to lowercase. (**2.00.10**)
  
- Added functions `splrep` and `splev` for cubic spline interpolation. (**2.00.10**)
  
- Added function `scs` to compute the optimal solution of linearly constrained linear or quadratic programming functions. (**2.00.10**)
  
- Added support for DECIMAL128 data type. (**2.00.10**)
  
- Added function `rowPrev`, `rowNext`, `rowMove`, `rowCumsum`, `rowCumprod`, `rowCummax`, `rowCummin` and `rowCumwsum` for row-based calculations. (**2.00.10**)
  
- Added function `temporalSeq` to generate time series at specified intervals. (**2.00.10**)

- Added function `ungroup` to flatten columns containing fast array vectors or columnar tuples. (**2.00.10**)
  
- Added function `decimalMultiply` to multiply data of DECIMAL types. (**2.00.10**)

- Added functions `base64Encode` and `base64Decode` to encode and decode Base64 digits. (**2.00.10**)
  
- Added function `addFunctionTypeInferenceRule` to specify the inference rule of user-defined functions in DolphinDB JIT version. (**2.00.10**)
  
- Added support for COMPLEX data type in DolphinDB JIT version. (**2.00.10**)
  
- Added configuration parameter *localSubscriberNum* to set the number of threads distributing the messages from the publish queue in local subscription. (**2.00.10**)

- Added function `createStreamDispatchEngine` to create a streaming data dispatch engine. (**2.00.10**)

- DECIMAL data is supported in the time series engine and reactive state engine when the following functions are used: (**2.00.10**)
  - Time Series Engine (created with `createTimeSeriesEngine`)：
    `corr`, `covar`, `first`, `last`, `max`, `med`, `min`, `percentile`, `quantile`, `std`, `var`, `sum`, `sum2`, `sum3`, `sum4`, `wavg`, `wsum`, `count`, `firstNot`, `ifirstNot`, `lastNot`, `ilastNot`, `imax`, `imin`, `nunique`, `prod`, `sem`, `mode`, `searchK`

  - Reactive State Engine (created with `createReactiveStateEngine`)：

    `cumsum`, `cumavg`, `cumstd`, `cumstdp`, `cumvar`, `cumvarp`, `cumcorr`, `cumbeta`, `cumcovar`, `cumwsum`, `cumwavg`, `msum`, `mavg`, `mstd`, `mstdp`, `mvar`, `mvarp`, `mcorr`, `mbeta`, `mcovar`, `mwsum`, `mwavg`, `tmsum`, `tmavg`, `tmstd`, `tmstdp`, `tmvar`, `tmvarp`, `tmcorr`, `tmbeta`, `tmwsum`, `tmwavg`

- Constants now can be declared as DECIMAL type with the data type symbol "P". (**2.00.9.4**)

- Added new configuration parameter `logicOrIgnoreNull`. The default value is true, which means to ignore NULL values in the operands. It should be set to false if you need the behavior of the `or` function to be consistent with old versions. (**2.00.9.4**)

- `is null` is now supported in a `case when` clause. (**2.00.9.4**)

- Added configuration parameter *mvccCheckpointThreshold* to set the threshold for the operations to trigger a checkpoint. (**2.00.9.3**)

- Added function `forceMvccCheckpoint` to manually trigger a checkpoint. (**2.00.9.3**)

- Added license server to manage resources for nodes specified by license. (**2.00.9**)
  - Related functions: `getLicenseServerResourceInfo`, `getRegisteredNodeInfo`.
  - Related configuration parameters: *licenseServerSite*, *bindCores*. 

- Added configuration parameter *thirdPartyAuthenticator* to authenticate user login over the third-party system. (**2.00.9**)

- Server version is now automatically checked when a plugin is loaded. (**2.00.9**)

- Support asynchronous replication across clusters for data consistency and offsite disaster recovery. (**2.00.9**)

- Support Apache Arrow format. (**2.00.9**)

- Added function `getTSDBSortKeyEntry` to show the sort key information of all chunks. (**2.00.9**)

- Added command `setMaxConnections` to dynamically configure the maximum connections on the current node. (**2.00.9**)

- Added function `demean` to center a data set. This function can be used as a state function in the reactive state engine. (**2.00.9**)

- Added parameter *ordered* for functions `dict` and `syncDict` to create an ordered dictionary where the key-value pairs are sorted in the same order as the input. (**2.00.9**)

- Added support for the following binary operations (**2.00.9**):
  - dictionary and dictionary
  - scalar and dictionary
  - vector and dictionary

- Added cumulative function `cumnunique` to obtain the cumulative count of unique elements. This function can be used as a state function in the reactive state engine. (**2.00.9**)

- Added function `stringFormat` to generate strings with specified values and placeholders. (**2.00.9**)

- Added function `rowAlign` to align data by row. (**2.00.9**)

- Added function `nanInfFill` to replace NaN and Inf values. (**2.00.9**)

- Added function `byColumn` to apply functions to each column of a matrix. The function is also supported in stream processing. (**2.00.9**)

- Added function `volumeBar` for data grouping based on the cumulative sum. (**2.00.9**)

- Added function `enlist` to return a vector (or tuple) with a scalar (or vector) as its element. (**2.00.9**)

- Added operator `eachAt(@)` to access elements of vector/tuple/matrix/table/dictionary/array vector by index. (**2.00.9**)

- Added new functions `latestKeyedTable` and `latestIndexedTable` to create a keyed table or indexed table with a time column. When a new record is appended to the table, it only overwrites the existing record with the same primary key if its timestamp is larger than the original one. (**2.00.9**)

- Support data form columnar tuple.  (**2.00.9**)
  - Related functions: `isColumnarTuple`, `setColumnTuple!`.

- Enhanced support for standard SQL features (**2.00.9**):
  - Clauses: `drop`, `alter`, `case when`, `union/union all`, `join on`, `with as`, `create local temporary table`
  - Predicates: `(not) between and`, `is null/is not null`, `(not) exists/not exist`, `any/all`
  - Functions: `nullIf`, `coalesce`
  - Keywords: `distinct`

- Support multiple joins, join with table aliases, and join with a table object returned by a SQL subquery. (**2.00.9**)

- SQL `select` can select a constant without specifying an alias, and the value will be used as the column name. (**2.00.9**)

- SQL predicates and operators can be applied to the result table returned by a SQL subquery. (**2.00.9**)

- Added configuration parameter *oldChunkVersionRetentionTime* to specify the retention time for old chunk versions in the system. (**2.00.9**)

- Support built-in trading calendars of major exchanges and user-defined trading calendars. These calendars can be used in functions `temporalAdd`, `resample`, `asFreq`, and `transFreq` for frequency conversion. (**2.00.9**)
  - Related configuration parameter: *marketHolidayDir*
  - Related functions: `addMarketHoliday`, `updateMarketHoliday`, and `getMarketCalendar` to add, update and get user-defined trading calendars.

- Added functions `genericStateIterate` and `genericTStateIterate` to iterate over streaming data with a sliding window. (**2.00.9**)

- Function `createWindowJoinEngine` supports array vectors. (**2.00.9**)

- Added functions `movingWindowData` and `tmovingWindowData` to obtain elements in a sliding window during stream processing. (**2.00.9**)

- Support `if-else` statement in the reactive state engine. (**2.00.9**)

- New SQL tracing tool for monitoring the time spent on the whole process of query execution. Added configuration parameter *traceLogDir* to specify the trace log path. (**2.00.8**)

- Added new function `truncate` for deleting the data in a DFS table while keeping the table schema. (**2.00.8**)

- Added new function `checkBackup` for checking the integrity of backup files. Added new function `getBackupStatus` for displaying the detailed information about database backup and restore jobs. (**2.00.8**)

- Added new functions `backupDB`, `restoreDB`, `backupTable`, and `restoreTable` for backing up / restoring an entire database or table. (**2.00.8**)

- Added new configuration parameter *logRetentionTime* for specifying the system log retention period. (**2.00.8**)

- Added new function `triggerNodeReport` for triggering a chunk information report for the specified data node. (**2.00.8**)

- Added new function `getUnresolvedTxn` for getting the transactions in the resolution phase. (**2.00.8**)

- The stream engine parser (`streamEngineParser`) now supports specifying user-defined functions with nested function as its *metrics*. (**2.00.8**)

- Added new function `conditionalIterate` for recursive computation of metrics through conditional iteration. This function can only be used in the reactive state stream engine (`createReactiveStateEngine`). (**2.00.8**)

- Added new function `stateMavg` for calculating the moving average based on previous results. This function can only be used in the reactive state stream engine (`createReactiveStateEngine`). (**2.00.8**)

- Function `mmaxPositiveStreak` can now be used in the reactive state stream engine (`createReactiveStateEngine`). (**2.00.8**)

- Added new function `stateIterate` for linear recursion by linear iteration. This function can only be used in the reactive state stream engine (`createReactiveStateEngine`). (**2.00.8**)

- Window join engine (`createWindowJoinEngine`): When the parameter *window*=0:0, the size of the calculation window over the right table is determined by the difference between the timestamps of the corresponding record in the left table and its most recent record. (**2.00.8**)

- Added support for new data type DECIMAL. Storage and computation involving the DECIMAL data type are also supported in some functions and the OLAP and TSDB storage engines. (**2.00.8**) 
  Note that:
  1. DECIMAL type columns cannot be specified as partitioning columns or sort columns (TSDB engine), or compressed using the "delta" method.
  2. DECIMAL type columns cannot be modified or deleted with the functions `addColumn`/`replaceColumn!`/`dropColumns!`/`rename!`
  3. The DECIMAL data type does not support stream data subscription and stream computing.
  4. loadText does not support importing columns containing DECIMAL values.

- Added new function `regroup` for grouped aggregation over a matrix based on user-specified column and/or row labels. (**2.00.8**)

- Added new functions `mifirstNot` and `milastNot` for returning the index of the first/last non-NULL element in a sliding window. (**2.00.8**)

- Added new function `loc` for accessing the rows and columns of a matrix by label(s) or a Boolean vector. (**2.00.8**)

- Added new function `til` for creating a vector of consecutive integers starting from 0. (**2.00.8**)

- Added new functions `pack` and `unpack` for packing and unpacking binary data. (**2.00.8**)

- Added new function `align` for aligning two matrices based on row labels and/or column labels using the specified join method. (**2.00.8**)

- DFS table join now supports full join. (**2.00.8**)

- DolphinDB (JIT) now supports accessing vector elements by index which can be a vector or a pair. (**2.00.8**)

- Web-based User Interface:
  - "Shell" tab enhancements: Added new "Database" view for checking databases and tables. (**2.00.8**)
  - Added new settings menu where you can customize the number of decimal places. For example, enter "2" to display numbers with 2 digits. (**2.00.8**)
  - Added support for visualization of dictionaries. (**2.00.8**)
  - You can now navigate to the associated documentation by clicking the error code (e.g., 'RefId: S00001'). (**2.00.8**)

- Added new configuration parameters *memLimitOfQueryResult* and *memLimitOfTaskGroupResult* to restrict the memory usage of the intermediate and final results of queries; new function `getQueryStatus` to monitor the memory usage and execution status of the query. (**2.00.7**)

- Added new function `getTSDBCompactionTaskStatus` to check the status of level file compaction tasks in the TSDB engine. (**2.00.7**)

- Added new functions `isPeak` and `isValley` to determine if the current element is the peak/valley of the neighboring elements. (**2.00.7**)

- Added new function `rowAt(X, Y)`. Return the element in each row of *X* based on the index specified by the corresponding element of Y. (**2.00.7**)

- Added new functions `rowImin` and `rowImax` to get the index of the extreme value in each row. (**2.00.7**)

- Added new machine learning function `gmm` to support Gaussian mixture model (GMM) clustering algorithms. (**2.00.7**)

- Added new function `valueChanged` to detect the change between elements by comparing the current element with adjacent elements.  (**2.00.7**)

- Added new functions `msum2` and `tmsum2` to calculate the sum of squares in a sliding window. (**2.00.7**)

- Added new functions `prevState` and `nextState` to find the element with a different state before/after the current element. (Consecutive elements with the same value are considered to be of the same state.)  (**2.00.7**)

- Added new function `getSupportBundle`. Return a file of support bundle containing system configuration and database information. (**2.00.7**)

- Added new functions `topRange` and `lowRange`. For each element in *X*, return the maximum length of a window to the left of *X* where it is the max/min. The functions are also supported in the reactive state engine (`createReactiveStateEngine`). (**2.00.7**)

- Added interpolation functions `spline`, `neville`, `dividedDifference`, and `loess`. (**2.00.7**)

- Added new parameter `cumPositiveStreak` for the reactive state engine (`createReactiveStateEngine`). (**2.00.7**)

- Added new streaming engine dual ownership reactive state engine (`createDualOwnershipReactiveStateEngine`) with support for parallel computing of data with 2 grouping methods and different metrics. (**2.00.7**)

- Introduced new table object "IPCInMemoryTable", interprocess in-memory table. Added related functions `createIPCInMemoryTable`, `loadIPCInMemoryTable`, `dropIPCInMemoryTable` and `readIPCInMemoryTable`. Interprocess in-memory table can be used in streaming scenarios to enable efficient data transfer between the DolphinDB server and client on the same machine. (**2.00.7**)

- Added new function `stretch` to stretch a vector evenly to the specified length. (**2.00.7**)

- Added new function `getTransactionStatus` to get the status of transactions. Added new command `imtForceGCRedolog` to skip the garbage collection of a transaction with the specified ID. (**2.00.7**)

- Added new module "ops" for database operations. This module contains some commonly-used scripts for operations such as cancelling unfinished jobs in the cluster, viewing disk usage of a DFS table, deleting recovering partitions, closing inactive sessions, etc. (**2.00.7**)

- Added new function `setLogLevel` to dynamically adjust the log level on the current node. (**2.00.7**)

* Added new function `cells` to retrieve multiple cells from a matrix by the specified row and col indices. (**2.00.6**)

* Added new function `randDiscrete` for sampling from a discrete probability distribution. (**2.00.6**)

* Added new functions `dynamicGroupCumsum` and `dynamicGroupCumcount`, and their state functions in the reactive state streaming engine. (**2.00.6**)

* Added new function `getTSDBCompactionTaskStatus` to get the status of level file compaction tasks of the TSDB engine. (**2.00.6**)

* Added new function `createDistributedInMemoryTable` to create a distributed in-memory table. (**2.00.6**)

* Support tiered storage to store cold data on slow hard disks or object storage (Amazon S3). These data are read-only. (**2.00.6**)

* Added new parameter *sortKeyMappingFunction* to function `createPartitionedTable` in the TSDB engine to apply mapping functions to the sortKey for optimal performance. (**2.00.6**)

* Optimized the update performance in the TSDB engine. (**2.00.6**)

* Added new function `toCharArray` to split a string into a vector of characters. (**2.00.6**)

* Added new configuration parameter *maxDynamicLocalExecutor* to specify the maximum number of dynamically-generated local executors and the frequency at which they are generated. (**2.00.6**)

* Added `transaction` statement to encapsulate multiple SQL statements on an in-memory table or a shared table into one transaction. (**2.00.6**)

* Support asynchronous data sorting in the TSDB cache engine. Specify the configuration parameter *TSDBAsyncSortingWorkerNum* as the number of threads for asynchronous sorting, and the default value is 1. (**2.00.5**)

* Snapshot isolation is supported in the TSDB engine. (**2.00.5**)

* The TSDB engine can be used on Windows. (**2.00.5**)

* You can enable dataSync for the OLAP engine by setting configuration parameter *dataSync* = 1 on Windows. (**2.00.5**)

* Added new parameters *userId* and *password* to function `subscribeTable`. The system will attempt to log in after a user is logged out accidentally to make sure the subscribed data can be written to a DFS table. (**2.00.5**)

* You can specify a function returning array vector for the parameter *metrics* of the reactive state streaming engine (`createReactiveStateEngine`). (**2.00.5**)

* Function `getStreamingStat().subWorkers` returns throttle in milliseconds. (**2.00.5**)

* You can specify multiple matching columns for the asof join engine. (**2.00.5**)

* Added new parameters *snapshotDir* and *snapshotIntervalInMsgCount* to the cross-sectional streaming engine to enable snapshot; Added new parameter *raftGroup* to enable high availability. (**2.00.5**)

* Added new functions `getLeftStream` and `getRightStream` to support cascade of join engines. (**2.00.5**)

* If a function with multiple returns is specified for the parameter *metrics* of a cross-sectional streaming engine (`createCrossSectionalEngine`) or a time-series streaming engine (`createTimeSeriesEngine`), the returned column names can be unspecified when creating the streaming engine. (**2.00.5**)

* Added new command `addAccessControl` to add access control on a shared in-memory table (stream table included) or the streaming engine object. (**2.00.5**)

* When applying an aggregate function, such as `quantile`, to a column in a table, if the data type of the column is not supported, the result is a NULL value. (**2.00.5**)

* The SQL `pivot by` clause supports columns of UUID type. (**2.00.5**)

* The upper limit of the result of function `ceil` or `floor` is raised to 2^53. (**2.00.5**)

* If the last column of a `pivot by` clause is a partitioning column, and no aggregate or order-sensitive functions are included in the `select` clause, the performance has been optimized by nearly five times. (**2.00.5**)

* Function `med`, `kama` and `wma` now support vectors of BOOL type. (**2.00.5**)

* The parameter *colNames* of command `addColumn` can start with a digit. (**2.00.5**)

* When loading a csv file with function `loadText` or `loadTextEx`,  the upper limit for the first row of data is raised to 256 KB. (**2.00.5**)

* Aggregate functions, window functions and vectorized functions support table as an input. (**2.00.5**)

* The parameter *count* of function `rand` or `normal` supports a pair to specify the dimension of a matrix. (**2.00.5**)

* Row-based logic functions (`rowAnd`, `rowOr` and `rowXor`) support input of INT type. (**2.00.5**)

* Added new parameter *arrayDelimiter* to functions `loadText` and `loadTextEx` to load csv files containing array vectors. (**2.00.5**)

* Added new parameter *closed* to function `bar` to specify whether the left or right boundary is inclusive in each group. (**2.00.5**)

* For a moving function, when *X* is an indexed series or an indexed matrix and *window* is a positive integer, the window slides over the index. (**2.00.5**)

* The parameters of a user-defined function can be defined across multiple lines and separated by a comma. (**2.00.5**)

* For a SQL `order by` clause, you can refer to a column by its name or the `as` alias. (**2.00.5**)

* You can now specify a vector of SECOND, TIME or NANOTIME type for the parameter *X* of function `dailyAlignedBar`. (**2.00.5**)

* The server can transfer tables containing array vectors to Python API in pickle format. (**2.00.5**)

* Added new parameter *forceTriggerSessionEndTime* to the daily time-series streaming engine to specify the waiting time to trigger calculation in the window containing *sessionEnd*. (**2.00.5**)

* Modified the parameter *forceTriggerTime* of the daily time-series streaming engine and the time-series streaming engine. The calculation in an uncompleted window of a group can be triggered by the latest ingested data of any other group. If the parameter *fill* is set, the specified filling methods are used to fill the results of the empty windows in the meantime. (**2.00.5**)

* Tables in the same partition can now be updated, written and deleted concurrently. (**2.00.4**)

* The type of data written into a temporal column of an in-memory table will be automatically converted to the data type of the column. (**2.00.4**)

* Data node can now be recovered online with the latest data from other nodes. You can also enable asynchronous recovery via configuration. (**2.00.4**)

* You can now manage and query all computing tasks in a cluster. (**2.00.4**)

* In-memory tables and stream tables now support data type BLOB. (**2.00.4**)

* You can now use a new tag [HINT_EXPLAIN] in your SQL statement to return a JSON string indicating the execution process of the statement. (**2.00.4**)

* Added new function `streamEngineParser` to decompose a cross-sectional factor into a pipeline with multiple built-in streaming engines. This function parses the specified metrics to construct a calculation pipeline, where multiple built-in engines process the streaming data in sequence. (**2.00.4**)

* Added new function `existSubscriptionTopic` to check whether a subscription topic has been created. (**2.00.4**)

* Added new function `createLookupJoinEngine` to support left join of a stream table and a table with infrequent data updates.  (**2.00.4**)

* Added new function `moveChunksAcrossVolume`. When a new volume is added, use this function to move chunks in the old volume to the new one.  (**2.00.4**)

* When a new volume is added, you can now use function `resetDBDirMeta` to move the old volume's meta log to the new one.  (**2.00.4**)

* Added 10 new TopN functions, `msumTopN`, `mavgTopN`, `mstdpTopN`, `mstdTopN`, `mvarTopN`, `mvarpTopN`, `mcorrTopN`, `mbetaTopN`, `mcovarTopN`, and `mwsumTopN`. These functions can be used as state functions in the reactive state engine. (**2.00.4**)

* Added new functions `makeKey` and `makeOrderedKey` to combine multiple columns into a BLOB column, so it can be used as the key of a dictionary or a set. (**2.00.4**)

* Added new higher-order function `aggrTopN`, which sorts data based on the specified sorting column and returns aggregate calculation results of the first N rows in the table. (**2.00.4**)

* Added new higher-order functions `window` and `twindow` for more general scenarios than `move` and `tmove`, with slightly different handling of window boundaries. (**2.00.4**)

* Added new configuration parameter *raftElectionTick*, which specifies the waiting time to receive a heartbeat from the leader in a raft group before the followers switch to a new leader. Added new functions `setCacheEngineMemSize`, `setTimeoutTick`, `setTSDBCacheEngineSize`, `setMaxMemSize`, `setReservedMemSize` and `setMaxBlockSizeForReservedMemory` to support modifying the associated configuration online. (**2.00.4**)

* Added new function `fixedLengthArrayVector` to combine multiple vectors into an array vector. (**2.00.4**)

* Added new function `loadNpz` to import *.npz* files from NumPy. (**2.00.4**)

* Added new function `suspendRecovery` to suspend node recovery tasks and added `resumeRecovery` to resume recovery tasks. (**2.00.4**)

* Added new functions `rowCorr`, `rowCovar`, `rowBeta`, `rowWsum` and `rowWavg` for row-based calculation. (**2.00.4**)

* Added new functions `movingWindowIndex` and `movingTopNIndex` to obtain index of the elements in a moving window. The result is an array vector of INDEX[] type. (**2.00.4**)

* Added new function `fflush` to flush buffer data to your file system. (**2.00.4**)

* Released the TSDB storage engine. The `database` function provides an optional parameter engineType, the default value is OLAP, which is the old storage engine. If you create a database based on the TSDB storage engine, set the engineType to TSDB. (**2.00.0**)

* The data based on the TSDB storage engine supports the new data type BLOB. (**2.00.0**)

### Improvements

- Configuration parameters *localExecutors* and *maxDynamicLocalExecutor* were discarded. (**2.00.10**)

- Functions `window` and `percentChange` can be used as state functions in the reactive state engine. (**2.00.10**)
  
- Support JOIN on multiple partitioned tables. (**2.00.10**)
  
- Optimized the performance when using the `dropTable` function to delete a table with a large number of partitions. (**2.00.10**)
  
- Optimized the performance when filtering data with a WHERE clause in a TSDB database. (**2.00.10**)
  
- Optimized the performance when joining tables of a TSDB database. (**2.00.10**)
  
- Enhanced support for standard SQL joins. The join column can be any column from tables or the column that is applied with functions or filtered by conditional expressions. (**2.00.10**)
  
- Support LEFT JOIN, FULL JOIN, and INNER JOIN on two tables with one table’s join column of STRING type and the other table’s of integral type. (**2.00.10**)
  
- Support SELECT NOT on DFS tables. (**2.00.10**)
  
- Support SQL keywords in all uppercase or lowercase. (**2.00.10**)
  
- Support comma (,) to CROSS JOIN tables. (**2.00.10**)
  
- Support line breaks for SQL statements, while keywords with multiple words, such as ORDER BY, GROUP BY, UNION ALL, INNER JOIN, cannot be split into two lines. (**2.00.10**)
  
- The implementation of  `select * from a join b` is changed from `select * from join(a, b)` to `select * from cj(a, b)`. (**2.00.10**)
  
- Support operator `<>` in SQL statements, which is equivalent to `!=`. (**2.00.10**)
  
- Support keyword NOT LIKE in SQL statements. (**2.00.10**)
  
- When LEFT JOIN, LEFT SEMI JOIN, RIGHT JOIN, FULL JOIN or EQUI JOIN on columns containing NULL values: (**2.00.10**)
  - In the previous versions: a NULL value is matched to another NULL.
  - Since the current version: a NULL value cannot be matched to another NULL.

- For function `sqlDS`, a DFS table partitioned by DATEHOUR selected in *sqlObj* will now be correctly filtered by date. (**2.00.10**)
  
- Optimized file merging for TSDB engine to reduce memory consumption. (**2.00.10**)
  
- Optimized storage architecture for TSDB engine with less blocks to reduce memory usage. (**2.00.10**)
  
- Added new parameters *defaultValues* and *allowNull* for function `mvccTable` to set the default values for columns and determine whether its columns can contain NULL values, respectively. It is now supported to modify column names and types, and delete columns of MVCC tables. (**2.00.10**)
  
- For the “Status” column returned by function `getRecoveryTaskStatus`, the previous status “Finish” is now changed to “Finished”, “Abort” to “Aborted”. (**2.00.10**)
  
- Optimized graceful shutdown, before which all symbol bases will be flushed to the disk. (**2.00.10**)
  
- Added inplace optimization fields, i.e., *inplaceOptimization* and *optimizedColumns*, when using `HINT_EXPLAIN` to check the execution plan of a GROUP BY clause when *algo* is “sort“. (**2.00.10**)
  
- Function `addColumn` now can add a column of DECIMAL type. (**2.00.10**)
  
- Optimized the performance when performing a point query on a table containing array vectors. (**2.00.10**)
  
- Optimized the execution logic for TSDB engine when compaction and partition drop are executed at the same time. (**2.00.10**)
  
- Added check for duplicated column names when updating column names with function `rename!`. (**2.00.10**)
  
- The column name specified with the `rename!`, `replaceColumn!`, `dropColumns!` functions are no longer case sensitive. (**2.00.10**)
  
- Added new parameters *swColName* and *checkInput* for the `lasso` and `elasticNet` functions to specify the sample weight and validation check, respectively. Added new parameters *swColName* for the `ridge` function. (**2.00.10**)
  
- Added parameters *x0*, *c*, *eps*, and *alpha* for function `qclp` to specify absolute value constraints, solving accuracy, and relaxation parameters. (**2.00.10**)
  
- Functions `loadText`, `pLoadText`, and `extractTextSchema` now can load a data file that contains a record with multiple newlines. (**2.00.10**)
  
- The *delimiter* parameter of the `loadText`, `pLoadText`, `loadTextEx`, `textChunkDS`, `extractTextSchema` functions can be specified as one or more characters. (**2.00.10**)
  
- When importing a table using function `loadTextEx`, an error will be reported if the table schema does not match the schema of the target database. (**2.00.10**)
  
- Added check for the *schema* parameter of function `loadTextEx`. Since this version, the table specified by schema MUST NOT be empty, and the "name" and "type" columns must be of STRING type. (**2.00.10**)
  
- An error will be reported when importing a table via function `loadTextEx` to an OLAP database with tables containing array vectors or BLOB columns. (**2.00.10**)
  
- Added new parameter *tiesMethod*, which is used to process the group of records with the same value, for the following moving TopN functions: `mstdTopN`, `mstdpTopN`, `mvarTopN`, `mvarpTopN`, `msumTopN`, `mavgTopN`, `mwsumTopN`, `mbetaTopN`, `mcorrTopN`, `mcovarTopN`. (**2.00.10**)
  
- The following functions support columnar tuple: `rowWavg`, `rowCorr`, `rowCovar`, `rowBeta`, and `rowWsum`. (**2.00.10**)
  
- Optimized the prediction performance of function `knn`. (**2.00.10**)
  
- The time series engine and daily time series engine now can output columns holding array vectors. (**2.00.10**)
  
- Optimized the performance of the `moving` function used in the reactive state engine. (**2.00.10**)
  
- The anomaly detection engine now can specify multiple grouping columns for parameter *keyColumn.* (**2.00.10**)
  
- The *window* parameter of function `genericStateIterate` now can be specified as 1. The performance is optimized when *window* is specified as 0 or 1.  (**2.00.10**)
  
- Added new parameter *sortByTime* for the `createWindowJoinEngine` and `createAsOfJoinEngine` functions to determine whether the result is returned in the order of timestamps globally. (**2.00.10**)
  
- Added check for the *T* parameter of function `genericTStateIterate`, which must be strictly increasing. (**2.00.10**)
  
- The streaming engine can now be shared with the `share` function/statement for concurrent writes. (**2.00.10**)
  
- An error will be reported when using the left semi join engine to subscribe to a table containing array vectors. (**2.00.10**)
  
- An error will be reported when using the `share` function/statement or the `enableTableShareAndPersistence` function to share the same table multiple times. (**2.00.10**)
  
- An error will be reported if the data of INT type is appended to a SYMBOL column of the left table of a window join engine. (**2.00.10**)
  
- Support pickle serialization of array vectors of UUID, INT128, and IP types. (**2.00.10**)

- DolphinDB JIT version supports the `join` operator (<-). (**2.00.10**)
  
- The `isort` function in JIT version can take a tuple with vectors of equal length as input. (**2.00.10**)
  
- The `if` expression in JIT version supports the `in` operator. (**2.00.10**)
  
- Vectors can be accessed with Boolean index in JIT version. (**2.00.10**)
  
- Support comments with multiple /\**/ sections in one line.  (**2.00.10**)

- The function `stringFormat` now supports: data type matching, format alignment, decimal digits, and base conversion. (**2.00.10**)
  
- The second parameter of function `concat` can be NULL. (**2.00.10**)
  
- Function `take` can take a tuple or table as input. (**2.00.10**)

- Function `stretch` can take a matrix or table as input.   (**2.00.10**)
  
- Functions `in` and `find` support table with one column. (**2.00.10**)
  
- When the parameter *moduleDir* is configured as a relative path, the system searches the modules under the *homeDir/modules* directory. (**2.00.10**)
  
- The result of function `in`, `binsrch`, `find`, or `asof` takes the same format as the input argument *Y*. (**2.00.10**)
  
- An error is raised when passing a tuple to function `rank`. (**2.00.10**)

- Added keyword `distinct` to eliminate duplicate records. It is currently not supported to be used with `group by`, `context by`, or `pivot by`. (**2.00.9.7**)

- The *outputElapsedInMicroseconds* parameter of function `createTimeSeriesEngine` is renamed to *outputElapsedMicroseconds*. (**2.00.9.4**)

- The fields "createTime" and "lastActiveTime" returned by function `getSessionMemoryStat` are now displayed in local time. (**2.00.9.4**)

- Enhanced support for `between and` with standard SQL features. (**2.00.9.4**)

- More operations on the IPC in-memory tables are logged for better tracking and debugging. (**2.00.9.4**)

- Function `getClusterDFSTables` returns DFS tables to which the user has access. (**2.00.9.3**)

- Parameter *leftTable* of function `createWindowJoinEngine` supports columns of array vectors. (**2.00.9.3**)

- Parameter *handler* of function `subscribeTable` supports shared in-memory table, keyed table, and indexed table. (**2.00.9.3**)

- Function `cut` now supports tables/matrices. (**2.00.9.3**)

- Ordered Dictionary now supports unary window functions. (**2.00.9.3**)

- Support checksum for the metadata files. (**2.00.9**)

- To avoid excessive disk usage of recovery log, recovery tasks now will be cleared for the follower which has been switched from the leader. (**2.00.9**)

- All backup and restore activities are fully logged. (**2.00.9**)

- Added new parameters *close*, *label*, *origin* for function `interval`. (**2.00.9**)

- Function `getRecentJobs` returns "clientIp" and "clientPort" indicating the client IP and port. (**2.00.9**)

- Added new parameter *warmup* for function `ema`. If set to true, elements in the first (window-1) windows are calculated. (**2.00.9**)

- The unary and ternary functions now can be specified for higher-order functions `accumulate` and `reduce`. (**2.00.9**)

- Added new parameter *outputElapsedMicroseconds* for the reactive state engine and time-series engine to output the elapsed time. (**2.00.9**)

- Support DECIMAL array vector. (**2.00.9**)

- Added new parameter *precision* for functions `rank` and `rowRank` to set the precision of the values to be sorted. (**2.00.9**)

- Parameter *mode* of function `groups` supports "vector" and "tuple". (**2.00.9**)

- Function `linearTimeTrend` supports calculations of a matrix or table. (**2.00.9**)

- Added support for iterations using multiple higher-order functions. Added new parameter *consistent* for higher-order functions `eachLeft`, `eachRight`, `eachPre`, `eachPost`, and `reduce` to determine the results' data type and form of tasks. (**2.00.9**)

- Function `objectChecksum` supports DECIMAL type. (**2.00.9**)

- Parameter *tiesMethod* of function `rank` and `rowRank` supports "first" to assign ranks to equal values in the order they appear in the vector. (**2.00.9**)

- Function `cut` now supports scalar. (**2.00.9**)

- Function `split` now supports STRING vector. (**2.00.9**)

- Function `rowAt` now supports array vector. (**2.00.9**)

- Rows of a matrix can now be accessed with `slice`. (**2.00.9**) 

- The size of a tuple is no longer limited to 1048576. (**2.00.9**)

- Enhanced support for DECIMAL type in most built-in functions. (**2.00.9**)

- The *defaultValue* argument passed to function `array` now supports STRING type. (**2.00.9**)

- Function `memSize` now returns the memory usage of tuple. (**2.00.9**)

- Query results of different partitions now can be combined through multiple threads to reduce the elapsed time of merge phase. (**2.00.9**)

- Function `getSessionMemoryStat` now returns related cache information. (**2.00.9**)

- Column comments now can be added to mvcc tables with `setColumnComment`. (**2.00.9**)

- Optimized the point query performance of TSDB engine. (**2.00.9**)

- Optimized the performance of select count(*) in the TSDB engine when keepDuplicates = last is specified. (**2.00.9**)

- Matrices now can be accessed with pair and vector as index. (**2.00.9**)

- Modified the actual available memory configured by *regularArrayMemoryLimit*. (**2.00.9**)

- Modified the upper limit on the number of DFS databases and tables. (**2.00.9**)

- For TSDB databases, data types of temporal sort keys can be automatically converted. (**2.00.9**)

- The publisher will push streaming data to the subscriber using the TCP connection established by the subscriber. The subscriber no longer needs to provide a listening port. (**2.00.9**)

- The reactive state engine supports the array vector with unfixed length. (**2.00.9**)

- The filter condition of function `streamfilter` supports built-in functions. (**2.00.9**)

- Added new parameter *sortColumns* for function `replay` to sort the data with the same timestamp. (**2.00.9**)

- Support automatic alignment of data sources for N-to-1 replay. (**2.00.9**)

- The window size is capped at 102400 when m-functions are used in the streaming engines. (**2.00.9**)

- Optimized the performance of heterogeneous replay. (**2.00.9**)

- Function `streamEngineParser` now supports function `byRow` nested with function `contextby` as metrics for the cross-section engine. (**2.00.9**)

- Support higher-order function `accumulate` in streaming. (**2.00.9**)

- Optimized the performance of function `genericTStateIterate`. (**2.00.9**)

- Optimized the performance of function `streamEngineParser`. (**2.00.9**)

- `append` / `insert into` operations on shared tables can be implemented with statement transaction. (**2.00.9**)

- Optimized the performance of `ej` on partitioned tables. (**2.00.9**)

- The `select` statement now supports using column alias or new column name as the filter condition in the `where` clause. (**2.00.9**)

- Optimized the performance of keyword `pivot by` when the last column is the partitioning column. (**2.00.9**)

- The keyword `context by` now supports specifying matrix and table. (**2.00.9**)

- Optimized the performance of `context by` and `group by`. (**2.00.9**)

- Optimized the performance of `lsj` at large data volumes. (**2.00.9**)

- The temporal data types in a SQL `where` clause can now be automatically converted when `interval` is used to group data. (**2.00.9**)

- The size of a tuple is no longer limited when used in SQL in condition. (**2.00.9**)

- Modified the return value of function `getSystemCpuUsage`. (**2.00.9**)

- Enhanced support for access control (**2.00.9**):

  - Extended privilege types at table level (TABLE_INSERT/TABLE_UPDATE/TABLE_DELETE) and database level (DB_INSERT/DB_UPDATE/DB_DELETE).
  - Modified DB_MANGE privilege which no longer permits database creations. Users with this privilege can only perform DDL operations on databases.
  - Modified DB_OWNER privilege which enables users to create databases with specified prefixes.
  - Added privilege types QUERY_RESULT_MEM_LIMIT and TASK_GROUP_MEM_LIMIT to set the upper limit of the memory usage of queries.
  - Access control-related functions now can be called on data nodes.
  - Modified the permission verification mechanism of DDL/DML operations.
  - Added parameter validation for access control:

    - An error is reported if the granularity of objs does not match the accessType of `grant`, `deny`, or `revoke`.
    - When the TABLE_READ/TABLE_WRITE/DBOBJ_*/VIEW_EXEC permission is granted, the existence of the applied object (database/table/function view) is checked first. If it does not exist, an error is reported.
    - When an object (database/table/function view) is deleted, the applied permissions are revoked. If a new object with the same name is created later, the permissions must be reassigned.
    - Permissions are retained for renamed tables.

- Optimized the performance of user-defined functions in streaming engines in DolphinDB (JIT).  (**2.00.9**)

- DolphinDB (JIT) supports operator `ratio`.  (**2.00.9**)

- DolphinDB (JIT) supports more built-in functions: `sum`, `avg`, `count`, `size`, `min`, `max`, `iif`, `moving`.  (**2.00.9**)

- Functions `backup`, `restore`, and `migrate` support backup and restore of database partitions by copying files. (**2.00.8**)

- Functions `replaceColumn!`, `rename!`, and `dropColumn!` now support DFS tables. (**2.00.8**)

- Added new parameter *deleteSchema* to function `dropPartition` to determine whether to delete the partition schema when deleting a VALUE partition. (**2.00.8**)

- Function `dropDatabase` deletes all physical files for the specified database. (**2.00.8**)

- Metacode of SQL statements can be passed to the parameter *obj* of function `saveText`. Partitions can be queried in parallel and written with a single thread. (**2.00.8**)

- The system raises an error message if you specify the configuration parameter *volumes* for a single node using macro variable `<ALIAS>`. (**2.00.8**)

- Support SQL `like` keyword in a `where` clause to search for a specified pattern of sort keys in the TSDB engine. (**2.00.8**)

- Optimized the reading performance in TSDB engine. (**2.00.8**)

- Optimized the performance of update, delete and upsert in the TSDB storage engine. (**2.00.8**)

- Added parameter *nullFill* to function `createWindowJoinEngine` to fill in the NULL values in the output table. (**2.00.8**)

- The parameter *timeRepartitionSchema* of function `replayDS` supports more temporal types. (**2.00.8**)

- Optimized the garbage collection logic of window join engine. (**2.00.8**)

- Identical expressions using user-defined functions are only calculated once in the reactive state stream engine. (**2.00.8**)

- Added SQL keyword `HINT_VECTORIZED` to enable vectorization for data grouping. (**2.00.8**)

- Optimized the query performance when the group by column is the VALUE partitioning column. (**2.00.8**)

- Optimized the performance of left join of an in-memory table and a DFS table. (**2.00.8**)

- Optimized the performance of SQL clause `pivot by`. (**2.00.8**)

- Optimized the computing performance of function `rolling`. (**2.00.8**)

- Function `getBackupList` returns column "updateTime" for the last update time and column "rows" for the number of records in a partition. (**2.00.8**)

- Added a new key "rows" to the dictionary returned by function `getBackupMeta` to show the number of rows in a partition. (**2.00.8**)

- Added optional parameter *containHeader* to functions `loadText`, `ploadText`, `loadTextEx`, and `textChunkDS` to indicate whether the file contains a header row. (**2.00.8**)

- Added access control to 31 functions, which can only be executed by a logged-in user or administrator. (**2.00.8**)

- `updateLicense` throws an exception if the authorization mode changed. (**2.00.8**)

- No exception is thrown if the indices are out of bounds when slicing a vector. (**2.00.8**)

- When accessing a vector by index, NULL values are returned if the indices are out of bounds in DolphinDB (standard and JIT version). (**2.00.8**)

- Optimized crc32 algorithm. (**2.00.8**)

- Optimized function `mrank`. (**2.00.8**)

- The maximum length for the data converted by function `toJson` is no longer limited to 1000. (**2.00.8**)

- Web-based User Interface:
    - Enhanced code highlighting to keep it consistent with the DolphinDB extension for Visual Studio Code. (**2.00.8**)
    - Numeric values are formatted with comma (,) as the thousands separator, e.g., `1,000,000,000`. (**2.00.8**)
    - Updated keywords, code completion, and function documentation. (**2.00.8**)
    - The execution information is displayed in a more compact layout. (**2.00.8**)
    - Enhanced the "status" popover view to display status information in different categories. (**2.00.8**)
    - Enhanced table pagination design and added tooltips for icon buttons. (**2.00.8**)
    - "Job" tab enhancements: Adjusted the field names; Added support for job search by client IP. (**2.00.8**)
    - Fixed an issue where the temporal labels were not correctly formatted in a `plot`. (**2.00.8**)

- `getClusterPerf(true)` returns the information on all controllers in a high-availability cluster. This function also adds a return value *isLeader* to indicate whether the controller is the leader of the raft group. (**2.00.7**)

- Now when connecting to a controller of a high-availability cluster on the web-based cluster manager, you will be redirected to the leader where information on all nodes are displayed. (**2.00.7**)

- When using function `restore`, `loadBackup`, or `getBackupMeta` to access the backup partitions in a database whose chunk granularity is at TABLE level, the physical index is no longer required when specifying the parameter *partition*. (**2.00.7**)

- Function `getRecoveryTaskStatus` adds a new return value *FailureReason* to display the reason for the recovery task failure. (**2.00.7**)

- Optimized the compression algorithm for `backup`. (**2.00.7**)

- If a *jobId* does not exist when using `cancelJob`, the system no longer throws an exception. Instead, it outputs the error message with the *jobId* to the log. (**2.00.7**)

- Now can specify the configuration parameter *persistenWorkerNum* for a high-availability stream table. (**2.00.7**)

- Added new parameter *forceTriggerTime* to `createSessionWindowEngine` to trigger the calculation in the last window if *useSystemTime*=false. (**2.00.7**)

- When processing standard stream tables with `streamFilter`, you can now specify metacode of Boolean expressions for the filter condition. (**2.00.7**)

- You can include the time column and/or join column from the left or right table as the output column(s) in the the parameter *metrics* of functions `createEqualJoinEngine`, `createAsofJoinEngine` and `createLookupJoinEngine`. (**2.00.7**)

- `replay` supports heterogeneous stream tables with columns of array vectors. (**2.00.7**)

- The parameter *keyPurgeFilter* of `createReactiveStateEngine` must be metacode of Boolean expressions, otherwise an error will be raised. (**2.00.7**)
- The parameter *metrics* of `createLookupJoinEngine` can be a tuple. (**2.00.7**)

- Optimized the performance of `select count(*)` when the time granularity of a `group by` clause is more coarse-grained than that of a partition. (**2.00.7**)

- Optimized the performance of querying the latest n records sorted in descending order with the `top` or `limit` clause. (**2.00.7**)

- Optimized the performance of the following functions when calling function `rolling`: `cumsum`, `cummax`, `cummin`, `cumprod`, and `mcount`. (**2.00.7**)

- tar.gz file for offline server installation. (**2.00.7**)

- Renamed the following configuration parameters and functions for the OLAP storage engine and the original names are used as aliases: *chunkCacheEngineMemSize* to *OLAPCacheEngineSize*, `purgeCacheEngine` to `flushOLAPCache`, `setCacheEngineMemSize` to `setOLAPCacheEngineSize`, and `getCacheEngineMemSize` to `getOLAPCacheEngineSize`. (**2.00.7**)

- Optimized the query performance by 2 times when the `context by` clause specifies a partitioning column. (**2.00.7**)

- Added configuration parameter *enableDropPartitionSchema* to delete the corresponding partitionSchema returned by function `schema` after calling `dropPartition`. (**2.00.7**)

- A subscription starts from the latest incoming data if the persisted offset cannot be found. (**2.00.7**)

- You can specify 00:00:00 for the parameter *sessionEnd* of function `createDailyTimeSeriesEngine` to indicate the end time is 00:00:00 of the next day (i.e., 24:00:00 of the day). (**2.00.7**)

- Function `trueRange` can be used as state function in the reactive state engine. (**2.00.7**)

- The number of rows in the result set of `fj` is limited to a maximum of 2 billion rows. (**2.00.7**)

* Optimized the performance of `select count(*)` on a table in the TSDB database. (**2.00.6**)

* Reduced the time to load the index of the TSDB storage engine. (**2.00.6**)

* Improved the performance of writing and reading SYMBOL type of data. (**2.00.6**)

* The window functions `cummed` and `cumpercentile` can now be used as state functions in the reactive state streaming engine (`createReactiveStateEngine`). (**2.00.6**)

* Added new parameter *closed* to time-series streaming engines (`createTimeSeriesEngine` and `createDailyTimeSeriesEngine`) to specify whether the left boundary or right boundary of the calculation window is inclusive. (**2.00.6**)

* The *keyColumn* parameter of `streamEngineParser` is now case-insensitive. (**2.00.6**)

* Added new parameter *keyPurgeFreqInSec* to time-series streaming engines (`createTimeSeriesEngine` and `createDailyTimeSeriesEngine`) to remove groups with no incoming data for a long time. (**2.00.6**)

* Optimized the performance for using user-defined functions in time-series streaming engines (`createTimeSeriesEngine` and `createDailyTimeSeriesEngine`). (**2.00.6**)

* `streamFilter` now supports processing columns of standard stream tables. Previously it only processes the output of heterogeneous `replay()`. (**2.00.6**)

* The *metrics* parameter of `createTimeSeriesEngine` and `createDailyTimeSeriesEngine` now supports matrices. (**2.00.6**)

* Now support queries where (1) the `group by` columns are not the partitioning columns, and (2) order-sensitive functions are applied to the queried columns. (**2.00.6**)

* The rule parameter of `resample` now supports "H", "L", "U", "min", "N", and "S". Added new parameters *closed*, *label*, and *origin* to set the interval of groups. (**2.00.6**)

* Function `byRow` now supports the array vector. (**2.00.6**)

* If an error is raised during the execution of the `replay` function, a runtime exception will be thrown. (**2.00.6**)

* Function `matrix` can convert a fixed length array vector to a matrix. (**2.00.6**)

* Optimized the performance of generating random integers. (**2.00.6**)

* The performance of querying the latest records of a certain column with TSDB engine is improved by up to hundreds of times. (**2.00.4**)

* Improved query performance of *top* clause in TSDB engine. (**2.00.4**)

* Improved performance of accessing precomputed data in TSDB engine. (**2.00.4**)

* When updating in-memory tables with assignment statements, you can now use BOOL arrays in row filters. For example, *t[`y, t[`y]>0] = 0* where *t* is a table and *y* is a column of *t*. (**2.00.4**)

* New optional parameter *sortColumns* is added to function `upsert!`. Use this parameter to specify the sorting columns based on which the updated table will be sorted. (**2.00.4**)

* `cancelJob` and `cancelConsoleJob` now support cancelling multiple jobs. Job cancelling is also faster when cluster is stuck. (**2.00.4**)

* The parameter *schema* in function `loadText` now supports array vector. (**2.00.4**)

* Function `set` now supports the BLOB data type. (**2.00.4**)

* Now multiple records with identical key values are not allowed to insert into a keyed stream table in one batch. (**2.00.4**)

* Faster execution speed for using functions `atImin` and `atImax` in widow join parameter *aggs*. (**2.00.4**)

* Added new optional parameter *clean* to the command `run` to control whether to clear the variables in current session. (**2.00.4**)

* The *window* parameter in function `wj` now supports duration types *y* (year), *M* (month) and *B* (business day). (**2.00.4**)

* Function `loadText` now supports strings containing characters with ASCII value 0. (**2.00.4**)

* You can now use conditional assignments on matrices. (**2.00.4**)

* Added a new optional parameter *atomic* to function `loadTextEx`. The default value is "false". When loading a large file, specify this parameter as "false" to split the loading transaction into multiple transactions. (**2.00.4**)

* Added new column *remoteIP* to the return value of functions `getCompletedQueries` and `getRunningQueries`. (**2.00.4**)

* Now you can specify the configuration parameter *stdoutLog* as "2" to print system log to both stdout and the log file. (**2.00.4**)

* The parameter *metrics* in anomaly detection engines can now contain sequence-related functions. (**2.00.4**)

* When the time-series engine parameter *windowSize* is a vector, the elements can take the same values. (**2.00.4**)

* Cross-sectional engine parameter *keyColumn* now supports vector type. (**2.00.4**)

* Records in tuple form can now be inserted to streaming engines. (**2.00.4**)

* New field *memoryUsed* is added to the return value of function `getStreamEngineStat().CrossSectionalEngine`, indicating the consumned memory of the cross-sectional engine. (**2.00.4**)
* In asof join engines, parameter *metrics* can now include the right table's temporal column. (**2.00.4**)

* Added read-only privilege for shared stream tables. (**2.00.4**)

* Improved stability of controller nodes in high availability clusters. (**2.00.4**)

* Information on delete and update operations can be printed in log. (**2.00.4**)

* Added subscription topic information to the error messages of the stream subscription task in the log. (**2.00.4**)

* UI enhancements for the Web-Based Cluster Manager. With the integrated user interface, you can now view, suspend and cancel jobs (running, submitted or scheduled) in DolphinDB. Note that after you have upgraded the server version, the "web" folder must be updated as well. The new version of Web-Based Cluster Manager uses the WebSocket protocol to enhance its support for binary protocols. Your web browser may need to be updated to the latest version. We recommend using the latest version of Chrome or Edge.  (**2.00.4**)

### Issues Fixed

- When querying a large DFS table using the SQL keyword TOP or GROUP BY, an error was potentially raised.  (**2.00.10**)

- When a SQL query specified a column name that couldn’t be recognized, the error message returned contained an incorrect column name instead of the actual unrecognized column name from the query. (**2.00.10**)

- Failures to write to a partition of a DFS table with many columns could cause the server to crash. (**2.00.10**)

- Concurrently loading and deleting multiple tables in a database could cause subsequent `loadTable` operations to fail with an error reporting it cannot find the *.tbl* file. (**2.00.10**)

- The `head` and `tail` functions could not be used in aggregate functions. This bug was introduced in DolphinDB 2.00.6. (**2.00.10**)

- A deadlock could occur when concurrently renaming a dimension table via `renameTable` and querying the same table.  (**2.00.10**)

- When querying a table with a large number of partitions using a SQL query with BETWEEN...AND... for partition pruning, the error `The number of partitions [xxxxx] relevant to the query is too large` could be raised.  (**2.00.10**)

- When using the TSDB storage engine and setting *keepDuplicates*=LAST on a table, the `UPDATE` statement behaved in a case-sensitive manner for column names. Starting in this release, column names is handled in a case-insensitive manner. (**2.00.10**)

- Using calculations or functions in a CASE WHEN condition could crash the server. (**2.00.10**)

- Using the DISTINCT keyword in SQL queries could return incorrect results. (**2.00.10**)

- The server could crash when the TSDB storage engine encountered an OOM error while writing data from memory to disk. (**2.00.10**)

- Attempting to write STRING data exceeding 256 KB in length to a table using the TSDB storage engine failed with the error `TSDBEngine failed to deserialize level file zonemap`. (**2.00.10**)

- When querying a VALUE or RANGE partitioned DFS table, if the SELECT clause and GROUP BY clause both applied the same time conversion function (e.g. `date()`) to the partitioning column, but used different aliases for that column, incorrect results could be returned. (**2.00.10**)

- When deleting data from a partitioned table using a SQL DELETE statement, if all nodes storing the replicas for the relevant partition were offline, the error `chunktype mismatched for path` could be raised. (**2.00.10**)

- The use of local executors could lead to deadlock situations during task scheduling. (**2.00.10**)

- In the DolphinDB JIT version, when appending large amounts of data to a reactive state engine (`createReactiveStateEngine`) that used user-defined functions, incorrect results could be returned. (**2.00.10**)

- A deadlock may occur when `unsubscribeTable` was called from multiple nodes simultaneously. (**2.00.10**)
  
- Server crashed when the capitalization of the column names specified in *metrics* and input tables of a left semi join engine (`createLeftSemiJoinEngine`) was inconsistent. (**2.00.10**)
  
- Server crashed when appending data to a stream table and persisting the table at the same time. (**2.00.10**)
  
- If the *metrics* of `createWindowJoinEngine` specified a column name alias, incorrect aggregate results were returned. (**2.00.10**)
  
- After `DROP table` was called to delete a stream table, the table could not be deleted or unsubscribed from. (**2.00.10**)
  
- Syntax parsing issues: statements such as `"/" == "a"` could not be parsed correctly. (**2.00.10**)

- An additional column was output when the second parameter of function `ols` consisted solely of 0. (**2.00.10**)
  
- The join results of DECIMAL data were incorrect. (**2.00.10**)

- Server crashed due to parsing failure when the parameter *aggs* of function `wj` was not compliant. (**2.00.10**)
  
- The result of function `expr` was incorrect if a DATEHOUR argument was passed. (**2.00.10**)
  
- The web interface could not be accessed properly if the parameter *webLoginRequired* was configured to true. (**2.00.10**)
  
- Incorrect results were returned when using `cast` to convert SYMBOL data. (**2.00.10**)

- Function `nullFill` failed to fill the NULL values returned by function `bucket`. (**2.00.10**)
  
- Precision loss occurred after applying `unpivot` to a column of DECIMAL type. (**2.00.10**)
  
- When a user-defined anonymous aggregate function was called with `twindow` in another user-defined function, an error `func must be an aggregate function.` was raised. (**2.00.10**)
  
- When a DolphinDB process was started, server crashed if a script (as configured with parameter *run*) containing function `submitJob` was executed. (**2.00.10**)

- A function name conflict occurred for the function view and module function at the server restart when the following conditions were satisfied at the same time(**2.00.9.7**):
  - in a standalone mode;
  - the function view was dropped after the module function was added to it;
  - the function defined in the module was passed to the addFunctionView, and the function view was dropped then;
  - the module was specified in the configuration parameter preloadModules to be preloaded.
 
  The error messages reported for other conflicts were enhanced.

- In a cluster mode, when SSL was enabled (*enableHTTPS=true*) for connection, the session may be disconnected if a large amount of data was transferred from the server to the client. (**2.00.9.7**)

- In a cluster mode, when joining tables under the same database (*atomic* = 'CHUNK') but on different nodes, incorrect results may be returned. (**2.00.9.7**)

- The reactive state engine did not handle the namespaces defined in *metrics*. (**2.00.9.7**)

- Incorrect results were returned by function `mskew` or `mkurtosis` if the input *X* contains consecutive identical values and the number of identical values is greater than *window*. (**2.00.9.7**)

- When a matrix is passed as an argument to the function `ols`, if the intermediate result is a singular matrix, the result is inconsistent with that of Python's `statsmodels.OLS`.  (**2.00.9.6**)

- An error occurred when using `order by` on columns of STRING type with `limit 0, k` or `limit k` on MVCC tables. (**2.00.9.5**)

- When deleting a function view with `dropFunctionView`, a server crash may occur due to the absence of locking during log writing. (**2.00.9.5**)

- When joining two tables with `equi join` or `inner join`, incorrect results were returned if the two matching columns are of STRING and NANOTIMESTAMP types. (**2.00.9.5**)

- When loading tables with `loadTable`, data loss may occur on the cold storage tier if the table names were improperly verified. (**2.00.9.5**)

- The `select distinct` statement is disabled. The keyword "distinct" is recognized as function `distinct`, i.e., the order of the elements in the result is not guaranteed to be the same as the input, and the column name is distinct_xxx. (**2.00.9.5**)

- When the configuration parameter *datanodeRestartInterval* was set to a time less than 100 seconds, the data node was immediately restarted by the controller in a graceful shutdown situation or after the cluster was restarted. (**2.00.9.4**)

- Incorrect conversion when the input of function `toJson` was a tuple which contains numeric scalars. (**2.00.9.4**)

- Incorrect conversion when the input of function `toJson` was a dictionary with its values being vectors of ANY type. (**2.00.9.4**)

- A server crash may occur when function `bar` with parameter *interval* set to 0 was used to query a partitioned table. (**2.00.9.4**)

- For N-to-1 replay, an error was reported when the key of the dictionary (set by parameter *inputTables*) was specified as SYMBOL type. This bug occurred since version 2.00.9. (**2.00.9.4**)

- Scheduled jobs failed to be executed due to the unsuccessful deserialization of file jobEditlog.meta at node startup. (**2.00.9.4**)

- Scheduled jobs were still executed until the next server startup, even though the serialization was unsuccessful when they were created. (**2.00.9.4**)

- A server crash occurred when the *defaultValue* parameter of function `array` is specified as a vector. (**2.00.9.4**)

- Passing non-table data to the *newData* parameter of `upsert!` could crash the DolphinDB server. (**2.00.9.4**)

- The `upsert!()` function would fail when the following three conditions were satisfied at the same time:

  - Only one record was to be updated
  - The newData parameter contained NULL values
  - The ignoreNull parameter was set to true

- Attempting to add multiple new columns to an MVCC table in an `update` statement would result in a data type error. (**2.00.9.4**)

- Using the `update...from...` statement to update a table (with keepDuplicates=LAST) in a TSDB database could produce incorrect results. (**2.00.9.4**)

- When specifying a column containing special characters such as control characters, punctuation marks, and mathematical symbols in the `group by` clause of a query, these special characters were improperly ignored. (**2.00.9.4**)

- After adding a column to a table of a TSDB database using `addColumn`, data errors and crashes may occur. (**2.00.9.4**)

- `dropColumns!` could not delete in-memory tables with sequential partitions. (**2.00.9.4**)

- A controller may crash when loading a partitioned table from the local disk. (**2.00.9.4**)

- Function `getClusterDFSTables` may return tables that have been deleted or do not exist. (**2.00.9.4**)

- The physical paths of partitions may not match the metadata after new data nodes are added and `moveReplicas()` is executed. (**2.00.9.4**)

- For N-to-N replay, if an element of the input data source for a table was empty, data in the output table may be misplaced. (**2.00.9.4**)

- Window join engine: Inconsistent row counts between the output table and the left input table when specifying *nullFill* as [[]] and *window* = 0:0. (**2.00.9.4**)

- Occasional failures of creating a streaming engine due to uninitialized internal variables. (**2.00.9.4**)

- For concurrent writes and queries to tables of a TSDB database, the query thread may crash when an OOM occurred. (**2.00.9.4**)

- For operations involving data flushing, data may be lost or the operations may get stuck if the physical directory of a partition did not exist (e.g., it had been manually deleted). (**2.00.9.4**)

- Incorrect result of the `temporalAdd` function when specifying the parameter unit as "M". (**2.00.9.4**)

- Data storage error may occur when different operations were performed on the same partition. (**2.00.9.3**)

- Users who are given DB_READ or TABLE_READ privileges may not be able to execute queries. (**2.00.9.3**)

- Server crashed in a high-availability cluster when reading raft logs at the reboot of the controller. (**2.00.9.3**)

- Server crashed when using `loadText` to load a CSV file that contains unpaired double quotes (""). (**2.00.9.3**)

- After new columns were added to an MVCC table, a server crash occurred when checking the table schema with function `schema` or adding comments to the new columns with function `setColumnComment`. (**2.00.9.3**)

- Invisible characters in the partitioning column resulted in inconsistent versions between controller and data node. (**2.00.9.3**)

- The TSDB engine did not automatically remove the cache of SYMBOL base in the memory. (**2.00.9.3**)

- Server crashed if the `byRow` function returned an arrayVector or anyVector when it applied a non-aggregate function to the input columnar tuple. (**2.00.9.3**)

- Server crashed when updating the in-memory table with index out of bounds. (**2.00.9.3**)

- A server crash may occur when users login frequently in high-concurrency scenarios. (**2.00.9.3**)

- Server crashed when a user-defined function was specified for the metric of function `StreamEngineParser`. (**2.00.9.3**)

- Window join engine: No output when parameter outputElapsedMicroseconds was set to true. (**2.00.9.3**)

- Lookup join engine: An OOM error occurred when the columns of input table contained array vectors. (**2.00.9.3**)

- When the stream table was not defined on the publisher, the reconnection on the subscriber resulted in file descriptor leaks. (**2.00.9.3**)

- Server crashed when using function `parseExpr` to convert a string containing a lambda function. (**2.00.9.3**)

- An error was reported when using function `parseExpr` to convert a string ending with a semicolon. (**2.00.9.3**)

- Server crashed when the following three conditions were satisfied at the same time: (**2.00.9.3**)
    - querying a composite-partitioned table with a group by clause;
    - using aggregate functions in select clause;
    - using functions, and the or function in the where clause.

- Server crashed when using function `RepartitionDS` to repartition a joined table and parameter *partitionType* is specified as VALUE. (**2.00.9.3**)

- If the matching columns of two partitioned table were not partitioning columns, and some partitioning columns of two tables have the same column name(s), incorrect result was returned when filtering the data with the partitioning columns of the right table. (**2.00.9.3**)

- For a DFS table value-partitioned by month,  an incorrect result was output when filtering the data on the first day of a month by the `where` condition. (**2.00.9.3**)

- Server crashed when using `order by` in conjunction with `limit` to sort column “DATE (case-sensitive)” in reverse order. (**2.00.9.3**)

- For a DECIMAL column being rearranged by a `pivot by` clause, an incorrect result was output when performing distributed computing such as `rowSum` on a column specified in `select`. (**2.00.9.3**)

- An incorrect result was output when performing time-series aggregate functions (e.g., `pre`, `rank`, etc.) on multiple columns. (**2.00.9.3**)

- An OOM error occurred for the TSDB engine during the compaction of level files and the generated level files were not properly garbage collected. (**2.00.9**)

- The data in the in-memory table returned by the aggregation function will be changed when it was subsequently calculated by moving functions such as move. The data in the in-memory table returned by the aggregation function will be changed when it was subsequently calculated by moving functions such as `move`. (**2.00.9**)

- An error was reported when anonymous aggregate function was specified for *aggs* of `window join`. (**2.00.9**)

- For a DFS table value-partitioned by month, an incorrect result was output if the temporal type specified in the `where` clause was inconsistent with that of table columns, and the where condition contained the last day of the month. (**2.00.9**)

- Server crashed when the independent variables (parameter X) of function ols was specified as a string. (**2.00.9**)

- Server crashed when using function loadText to import data of string type. (**2.00.9**)

- Server crashed when an MVCC table is used in a transaction statement. (**2.00.9**)

- Incorrect results for using `as` with function `deltas` in conjunction with function `corr`. (**2.00.9**)

- An error was reported for function `upsert!` when the TSDB engine contained columns of array vector. (**2.00.9**)

- Terminating the DolphinDB process with kill-9 command may cause redo logs not to be removed. (**2.00.9**)

- A crash may occur when a table containing string columns was calculated in a reactive state engine. (**2.00.9**)

- Submitting a metacode containing undefined variables via `submitJob` resulted in a crash. (**2.00.9**)

- A node crash may occur after recovery from network failure in a cluster. (**2.00.9**)

- Using partial application in metaprogramming with `context by` could obtain incorrect results. (**2.00.9**)

- *sqlObj* could not be recognized as metacode in `replayDS`. (**2.00.9**)

- Server crashed when an array vector was sorted by function `rank`. (**2.00.9**)

- If the left table of `lj` is an in-memory table and the right one is a DFS table which is located under a multilevel directory (e.g., *dfs://mydbs/quotedb*), an error would be reported. (**2.00.9**)

- An error was reported when the *metric* of function `createTimeSeriesAggregator` contained a keyColumn. (**2.00.9**)

- The trace function resulted in file descriptor leaks. (**2.00.9**)

- The `getClusterPerf` function caused deadlocks when executed by two nodes at the same time in a high-availability cluster. (**2.00.9**)

- A crash may occur when the `accumulate` function was executed multiple times. (**2.00.9**)

- After the execution of function `createDailyTimeSeriesEngine` was completed, an error may be reported for the data of temporal type in query results in some scenarios. (**2.00.9**)

- For a partitioned table with *sortKeyMappingFunction* specified in a TSDB database, concurrent queries with multi-threading may cause an error or a crash. (**2.00.9**)

- Unexpected result returned by function `isValid` when adding two empty strings. (**2.00.9**)

- Null values were returned when more than 128 filtering conditions connected with keyword `or` were specified in the where clause. (**2.00.9**)

- An exception thrown by function `loadText` may lead to deadlocks under high load. (**2.00.9**)

- After the function was added to function view, the body queried by function `getFunctionView` had one less pair of brackets. (**2.00.9**)

- When a row was accessed from a table using index, incorrect result was returned for fields of type array vector. (**2.00.9**)
  
- Server crashed when a string vector was retrieved by slicing with index out of bounds. (**2.00.9**)

- A crash may occur when using higher-order function each to apply a user-defined function to a table. (**2.00.9**)

- An error was reported if minPeriods was set greater than or equal to 2 when calculating array vectors using the `moving` function in memory. (**2.00.9**)

- No exception was thrown when the data appended to the cross sectional engine did not match the schema of dummy table. (**2.00.9**)

- Using function `restoreDB` to restore a TSDB database caused a deadlock. (**2.00.9**)

- When joining DFS tables with the matching column different from the partitioning column, if the join result was queried by a `select top` clause and `order by` partitioning column, an incorrect result was returned. (**2.00.9**)

- An error was reported when using function `rpc` or `remoteRun` to call a partially applied function. (**2.00.9**)

- The file storing job logs was lost when it reached 1G. (**2.00.9**)

- The number of openBLAS-threads was determined based on the configuration parameter openblasThreads, not on the number of CPU cores. (**2.00.9**)

- Memory leak occurred when writing STRING type data to a table in a TSDB database. (**2.00.8**)

- The TSDB engine failed to flush data when configuring the parameter *TSDBCacheFlushWorkNum* to a value less than *volumes*. (**2.00.8**)

- Serialization on a data node failed if the metadata of a partition exceeded 128M. (**2.00.8**)

- DDL operations on a data node caused partition status errors due to transaction resolution failure. (**2.00.8**)

- Failure of replaying redo log resulted in partition status errors on the data node. (**2.00.8**)

- Partition was wrongly deleted due to migration failure when the partition was moved to the configured *coldVolume* of tiered storage. (**2.00.8**)

- When creating a database with atomic='CHUNK', slow startup occurred due to excessive metadata on the controller. (**2.00.8**)

- Deleting a DFS table in a TSDB database with `delete` caused excessive memory usage. (**2.00.8**)

- Old data was prematurely reclaimed after update. (**2.00.8**)

- The original table was not immediately reclaimed after the `renameTable` operation was performed. (**2.00.8**)

- Server crashed when specifying a partition path ended with a "/" for function `dropPartition`. (**2.00.8**)

- Users cannot delete partitions that were automatically added when creating a DFS table with VALUE-based partitions by specifying conditions for `dropPartition`. (**2.00.8**)

- Repeated deletions on an empty table caused cid errors in the metadata stored on the data node. (**2.00.8**)

- The parameter *dfsRecoveryConcurrency* did not take effect after configuration. (**2.00.8**)

- When inserting an array vector into a stream table, the subscription handler failed. (**2.00.8**)

- Server crashed when passing array vectors to a user-defined function specified for the *metrics* of `createReactiveStateEngine`. (**2.00.8**)

- `createReactiveStateEngine` failed when specifying factor `tablibNull` for the *metrics*. (**2.00.8**)

- Server crashed when specifying external variables for the *metrics* of `streamEngineParser`. (**2.00.8**)

- Server crashed when the row count of the left table was smaller than the window size in `window join`. (**2.00.8**)

- Server crashed when using `exec` with `limit` and the number of returned rows is less than `limit`. (**2.00.8**)

- The `isDuplicated` and `nunique` functions returned incorrect results when working with DOUBLE and FLOAT data types. (**2.00.8**)

- Calling `parseExpr` in user-defined functions caused parsing failure. (**2.00.8**)

- The function `getClusterPerf` returned incorrect value of *maxRunningQueryTime*. (**2.00.8**)

- Server crashed when using `loadNpy` to read excessively large npy files. (**2.00.8**)

- Variables defined within a for-loop could not be accessed outside the loop using DolphinDB JIT version. (**2.00.8**)

- Garbage collection of redo log got stuck when data was continuously written to an OLAP database. (**2.00.7**)

- A node was wrongly considered alive by the controller after graceful shutdown. (**2.00.7**)

- Partition locks were prematurely released due to timeout before a transaction was resolved, which led to write failure. (**2.00.7**)

- Query conditions were wrongly processed when backing up data by specifying the conditions. (**2.00.7**)

- Server crashed when the machine load was excessively high. (**2.00.7**)

- When a cluster was restarted after a DFS table was updated, the original physical directories may not be recycled. (**2.00.7**)

- Serialization failure of symbol base caused read errors. (**2.00.7**)

- Streaming subscription failed to obtain data that was in memory but had been deleted from disk. (**2.00.7**)

- Server crashed when the number of columns inserted by `appendForJoin` did not match the table schema of the left or right table of a join engine. (**2.00.7**)

- When the parameter *updateTime* of function `createSessionWindowEngine` was specified and the output table was not a keyed table, the calculation could not be triggered after 2 * *updateTime* when a record arrived. (**2.00.7**)

- Server crashed when data was continuously ingested to a daily time series engine after the session end. (**2.00.7**)

- Failed to create a lookup join engine when the right table was specified as a shared keyed table. (**2.00.7**)

- If a node was restarted when a stream table was persisted to disk, data loss and decompression failure may occur. (**2.00.7**)

- Server crashed when specifying a time column (of a big array form) for *dateColumn* and *timeColumn* of `replay` and setting *absoluteRate*=false. (**2.00.7**)

- No error was reported when specifying a user-defined function with a constant return value for the *metrics* of a reactive state engine. (**2.00.7**)

- Server crashed when specifying temporary variables for *metrics* of `createAnomalyDetectionEngine`. (**2.00.7**)

- Error "The select clause of the query doesn't refer any column." was reported when performing `context by` operations on a DFS table using metaprogramming. (**2.00.7**)

- When using SQL `update` with `context by`, if the first column was set to integral type and the subsequent columns were set to floating-point types, values in the floating-point columns were rounded. (**2.00.7**)

- Concurrent `pivot by` queries may get stuck with few number of worker threads. (**2.00.7**)

- Server crashed when using `HINT_EXPLAIN` to query data from a three-level partitioned table. (**2.00.7**)

- Incorrect results when using function `binsrch` on a subarray of STRING type. (**2.00.7**)

- Function `cast` returned empty when converting a vector of STRING type to a tuple. (**2.00.7**)

- When aggregating multiple INT128 columns of an in-memory table, an error “The function min for reductive operations does not support data type INT128” occurred. (**2.00.7**)

- `getFunctionView` did not return some function view bodies. (**2.00.7**)

- Incorrect result of applying function `removeHead!` to array vectors. (**2.00.7**)

- Server crashed when an empty tuple was appended to itself and then loaded. (**2.00.7**)

- Server crashed when using `interval` interpolation in a SQL query, if the granularity of the data type specified for the time range in the where clause is greater than the time granularity specified by the *duration* parameter of `interval`. (**2.00.7**)

- Server crashed when using the function `twindow` in a SQL query. (**2.00.7**)

- `update` on a DFS table failed when the set column names did not match the original column names (including case sensitive inconsistencies). (**2.00.7**)

- When the function `iterate` was included in the *metrics* of a reactive state engine and the data cleaning mechanism was enabled, if data was inserted while the historical data was being cleaned, an error "vector::_M_default_append" was reported. (**2.00.7**)

- When calling `matrix([[datehour(0)],[datehour(0)]])` to create a matrix, an error "The data object for matrix function can't be string or any type" was reported. (**2.00.7**)

- When specifying `countNanInf` for the parameter *aggs* of function `wj`, an error "An window join function must be an aggregate function" was reported. (**2.00.7**)

- If no group was specified for `createDailyTimeSeriesEngine`, any uncalculated data from the previous day would be merged into the first window of the following day. (**2.00.7**)

- The first window's calculation result across days in a daily time series engine was incorrect. Additionally, when the function `fill` was used to fill in NULL values, data outside the session was output. (**2.00.7**)

- Tasks in *In-Progress* state could not be recovered during online recovery. (**2.00.7**)

- Server crashed when specifying *useSystemTime*=true and `mode` for *metrics* of  `createTimeSeriesEngine`*.* (**2.00.7**)

- When specifying the `tmove` or `move` function for the metrics of `createReactiveStateEngine`, the server would crash if *X* was of the STRING or SYMBOL type. (**2.00.7**)

- Incorrect results of function `wj` when specifying `atImax` or `atImin` for *aggs*. (**2.00.7**)

- Failed to insert data with `tableInsert` when splitting and assigning a stream table with `streamFilter`. (**2.00.7**)

- The insert failure of `streamFilter` may cause session disconnection due to excessively long error messages. (**2.00.7**)

- When specifying function `firstNot` or `lastNot` for the *metrics* of `createTimeSeriesEngine` or `createReactiveStateEngine` and setting *fill*=`ffill, the output did not match expectations. (**2.00.7**)

- Server crashed when specifying function `mfirst` or `mlast` for the *metrics* of `createReactiveStateEngine`, and *X* was of FLOAT, SHORT, CHAR, BOOL, INT128, STRING, or SYMBOL type. (**2.00.7**)

- Executing function `tableInsert` changed the atomic level of a database from 'CHUNK' to 'TRANS'. (**2.00.7**)

- When specifying tm-functions for the *metrics* of `createReactiveStateEngine` and the *window* parameter of the function is set to y, M or B, the calculation result was incorrect. (**2.00.7**)

- File descriptor leaked when using the TSDB engine of version 2.00.6 on Windows. (**2.00.7**)

- Inconsistent STRING columns between replicas after online recovery. (**2.00.7**)

- When passing TIME type data to *index* of `resample` and setting *origin*=”end” and *rule*=”D”, an error "Invalid value for HourOfDay (valid values 0 - 23): 39" was reported. (**2.00.7**)

- An error was reported when administrators (except the super admin) granted/denied/revoked permissions to themselves. (**2.00.7**)

- Redo log recycling exception when OOM occurred in TSDB engine. (**2.00.7**)

- Calculating `imin` or `imax` with `byRow` on a matrix with an empty row returned incorrect results. (**2.00.7**)

- Function `getControllerPef` returned incorrect agent site when a controller crashed. (**2.00.7**)

- Server crashed when calling `interval` in a SQL query and aggregating the data with a user-defined function. (**2.00.7**)

- When *dataSync* was not configured, an error occurred when dynamically calling the `addNode` function to add a node. (**2.00.7**)

* An OOM error caused by concurrent writes, queries or calculations may lead to a server hang-up. (**2.00.6**)

* If data deduplication is enabled in the TSDB engine, when writes and reads are conducted at the same time, the result may be incorrect. (**2.00.6**)

* When writes and reads are conducted in the OLAP engine at the same time, the result may be incorrect. (**2.00.6**)

* A query using `exec` with `limit 1` in the TSDB engine returns a table rather than a vector. (**2.00.6**)

* When writing to an OLAP cache engine, if an exception other than OOM occurs, the system will repeatedly attempt to rewrite, which leads to a server hang-up. (**2.00.6**)

* If a data node is started via the web interface or a cluster is restarted repeatedly, defunct processes are generated. (**2.00.6**)

* If `moveReplicas` is called after executing `suspendRecovery`, it fails to move some of the chunks. (**2.00.6**)

* If a cluster is rebooted after submitting concurrent tasks, some chunks are always in the status of RECOVERING. (**2.00.6**)

* If `delete` is used to delete large amount of data, incorrect information may be written to the checkpoint file, which causes a node to crash and cannot be restarted. (**2.00.6**)

* If snapshot is enabled in the reactive state streaming engine, resubscription to a table with different metrics causes a server crash. (**2.00.6**)

* Appending a single record to the lookup join engine may cause a server crash. (**2.00.6**)

* If the data written to a high-availability stream table are in different schema, they can still enter the persistent queue, and the error "Can't find the object with name" is reported after a leader switch. (**2.00.6**)

* If the parameter *fill* is specified for `createDailyTimeSeriesEngine`, the result of date without data is filled. (**2.00.6**)

* A non-admin user can use function `createUser`. (**2.00.6**)

* The command `changePwd` does not limit the length of the new password. (**2.00.6**)

* If an array vector takes up large amount of memory but does not reach warningMemSize, an OOM error is raised. (**2.00.6**)

* `matrix([],[])` leads to a server crash. (**2.00.6**)

* When using `exec` with `pivot by`, if no function is used on the `exec` column, the statement will generate a table, rather than a matrix. (**2.00.6**)

* If numJobs > 1 or numJobs = -1 is set in function `randomForestClassifier` for concurrent jobs, a repeated use of dataSource leads to a server crash. (**2.00.6**)

* If the parameter duration of function `interval` has different precision with that of the parameter X, a crash occurs. (**2.00.6**)

* When creating an in-memory keyed table with `keyedTable(keyColumns, table)`, if the keyColumns in the table have duplicate values, a memory leak occurs. (**2.00.6**)

* For moving functions that can be used on matrices, such as `mcorr` and `mwavg`, when calculating on indexed matrices, the label column may be lost in the result. (**2.00.6**)

* Function `LoadTextEx` does not report an error when an exception of data loading occurs since 2.00.4. (**2.00.6**)

* A redo log recovery timeout may occur when a transaction is slowly synchronized to disk, resulting in data loss after the server restarts. (**2.00.4**)

* A data node fails to start and reports the error message "Failed to open public key file. No such file or directory" when starting multiple DolphinDB clusters on one server. (**2.00.4**)

* A scheduled job on a high availability cluster may fail to execute due to authentication failure of the switched leader because the initial UUIDs are different between controllers. (**2.00.4**)

* After a data node crashes, the agent node reboots the offline node every second instead of at specified intervals configured in parameter *datanodeRestartInterval*. (**2.00.4**)  

* When the parameter *jobFunc* of `scheduleJob` contains a SQL update statement and a where clause with functions, the deserialization fails after the system restarts. (**2.00.4**)

* After updating a distributed table, the original physical directories are not recycled if the transaction fails to commit.  (**2.00.4**)

* In a high concurrency scenario, a fully-occupied disk of the redo log may cause deadlock in the redo log recovery thread.  (**2.00.4**)

* If an OOM event occurs when writing to a data node, the node crashes after being stuck for a while instead of reporting the error. (**2.00.4**)  

* For a table partitioned by *timeCol* with more than 2 *sortColumns* (where the *timeCol* is the last column), the TSDB engine may crash when querying the table to obtain the first k rows of records grouped by *sortColumns* and sorted by *timeCol* (`context by sortColumns csort timeCol limit k`). (**2.00.4**) 

* When conducting concurrent modifications to the edit log in the TSDB engine, the data node fails to restart. (**2.00.4**)

* The chunk state is wrongly set when a transaction rollback times out, causing persistence failure in the stream table. (**2.00.4**)

* Parameter validation error with function `createCrossSectionalEngine`: When *timeColumn* is specified without setting *useSystemTime* to be true, the error is not raised. (**2.00.4**) 
 
* For a time-series streaming engine, when *useSystemTime* is set to be true and *outputTable* is a distributed table, an exception of data type mismatch may be raised. (**2.00.4**)

* If *delayedTime* is specified in the asof join streaming engine, write operations may lead to server crash. (**2.00.4**)

* When appending more than 65536 rows of records to a high availability stream table twice and rollback occurs, the index.log reports an error "index.log contains invalid data" as two identical indices are written. (**2.00.4**)

* Writing to a time-series streaming engine, daily time-series streaming engine or asof join streaming engine may lead to a server crash on Windows. (**2.00.4**)

* When the subExecutor thread still has tasks in progress, after successfully executing `unsubscribeTable`, `getStreamingStat().subWorkers` still returns the unsubscribed topics. (**2.00.4**)

* Loading a high availability stream table may fail after a node restarts. (**2.00.4**)

* Reconnection fails after switching leaders in the raft groups of the stream table and the subscriber. (**2.00.4**)

* When *triggeringPattern* = 'keyCount' and *triggeringInterval* is a tuple, `createCrossSectionalEngine` returns duplicate results. (**2.00.4**)

* Error "Failed to decompress the vector. Invalid message format" occurs when loading a persisted stream table containing BLOB data. (**2.00.4**)

* Crash occurs when writing BLOB data to a stream table and a single record exceeds 64KB. (**2.00.4**)

* After assigning values to an added column in an in-memory table with `select` statement instead of `exec` statement, the node crashes when loading the table. (**2.00.4**)

* When accessing an in-memory table with array vectors via GUI, the session is disconnected from the server. (**2.00.4**)

* An error "Read only object or object without ownership can't be applied to mutable function readRecord!" occurs when loading binary files with function `readRecord!`. (**2.00.4**)

* The parser may report an error for function calls when the right bracket is not placed on the same line as the left bracket. (**2.00.4**)

* Executing function `replayDS` on a table with array vectors causes a node crash. (**2.00.4**)

* When querying a partitioned table with value domain for the last k rows of records in each group (`context by partitionCol limit -k`), some of the results do not satisfy the where conditions if no eligible data exists in a partition. (**2.00.4**)

* An error "More than one column has the duplicated name" occurs when calling function `rolling` or `moving` in SQL statement without specifying the generated column name. (**2.00.4**)

* NULL values are generated if no data is found in a *step* duration of function `interval`. (**2.00.4**)

* Wrongly-specified parameter *rowKeys* of function `sliceByKey` leads to server crash. (**2.00.4**)

* Null flag is not set after `replace!` a vector with NULL values. (**2.00.4**)

